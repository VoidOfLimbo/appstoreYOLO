{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612df05b",
   "metadata": {},
   "source": [
    "# YOLOv8 Object Detection Training\n",
    "\n",
    "This notebook demonstrates how to train and fine-tune YOLOv8 models for object detection.\n",
    "\n",
    "## Requirements\n",
    "- ultralytics\n",
    "- PyTorch with CUDA support\n",
    "- Custom dataset in YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72644dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32334881",
   "metadata": {},
   "source": [
    "## 1. Load Pre-trained Model\n",
    "\n",
    "Start with a pre-trained YOLOv8 model. Available sizes:\n",
    "- `yolov8n.pt` - Nano (fastest, smallest)\n",
    "- `yolov8s.pt` - Small\n",
    "- `yolov8m.pt` - Medium\n",
    "- `yolov8l.pt` - Large\n",
    "- `yolov8x.pt` - Extra Large (most accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d24b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model_path = '../models/detection/yolo/yolov8s.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(f\"Model loaded: {model_path}\")\n",
    "print(f\"Model task: {model.task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26907bec",
   "metadata": {},
   "source": [
    "## 2. Prepare Your Dataset\n",
    "\n",
    "Your dataset should be in YOLO format:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── data.yaml\n",
    "├── train/\n",
    "│   ├── images/\n",
    "│   └── labels/\n",
    "└── val/\n",
    "    ├── images/\n",
    "    └── labels/\n",
    "```\n",
    "\n",
    "The `data.yaml` file should contain:\n",
    "```yaml\n",
    "train: train/images\n",
    "val: val/images\n",
    "nc: 2  # number of classes\n",
    "names: ['class1', 'class2']  # class names\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a sample data.yaml configuration\n",
    "dataset_config = \"\"\"\n",
    "# Dataset configuration for YOLOv8\n",
    "path: ./dataset  # dataset root directory\n",
    "train: train/images  # train images relative to 'path'\n",
    "val: val/images  # validation images relative to 'path'\n",
    "\n",
    "# Classes\n",
    "nc: 80  # number of classes (COCO has 80 classes)\n",
    "names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', \n",
    "        'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', \n",
    "        'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', \n",
    "        'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', \n",
    "        'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', \n",
    "        'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', \n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', \n",
    "        'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', \n",
    "        'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\"\"\"\n",
    "\n",
    "print(\"Dataset configuration example:\")\n",
    "print(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7668f",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "Configure training parameters and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_params = {\n",
    "    'data': 'coco128.yaml',  # or path to your custom data.yaml\n",
    "    'epochs': 100,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'device': 0,  # GPU device (0 for first GPU, 'cpu' for CPU)\n",
    "    'workers': 8,\n",
    "    'project': 'runs/detect',\n",
    "    'name': 'yolov8_custom',\n",
    "    'patience': 50,  # early stopping patience\n",
    "    'save': True,\n",
    "    'save_period': 10,  # save checkpoint every N epochs\n",
    "    'cache': False,  # cache images for faster training\n",
    "    'optimizer': 'Adam',  # SGD, Adam, AdamW\n",
    "    'lr0': 0.01,  # initial learning rate\n",
    "    'lrf': 0.01,  # final learning rate factor\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'box': 7.5,  # box loss gain\n",
    "    'cls': 0.5,  # cls loss gain\n",
    "    'dfl': 1.5,  # dfl loss gain\n",
    "    'pose': 12.0,  # pose loss gain\n",
    "    'kobj': 2.0,  # keypoint obj loss gain\n",
    "    'label_smoothing': 0.0,\n",
    "    'nbs': 64,  # nominal batch size\n",
    "    'overlap_mask': True,\n",
    "    'mask_ratio': 4,\n",
    "    'dropout': 0.0,\n",
    "    'val': True,  # validate during training\n",
    "}\n",
    "\n",
    "print(\"Training parameters:\")\n",
    "for key, value in training_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc51601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training (uncomment to run)\n",
    "# results = model.train(**training_params)\n",
    "\n",
    "# For quick testing with COCO128 dataset:\n",
    "# results = model.train(data='coco128.yaml', epochs=3, imgsz=640, batch=4)\n",
    "\n",
    "print(\"Training ready to start. Uncomment the code above to begin training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fae4b4",
   "metadata": {},
   "source": [
    "## 4. Validate the Model\n",
    "\n",
    "Evaluate model performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the trained model\n",
    "# metrics = model.val()\n",
    "\n",
    "# print(\"\\nValidation Metrics:\")\n",
    "# print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
    "# print(f\"mAP50-95: {metrics.box.map:.3f}\")\n",
    "# print(f\"Precision: {metrics.box.mp:.3f}\")\n",
    "# print(f\"Recall: {metrics.box.mr:.3f}\")\n",
    "\n",
    "print(\"Validation ready. Uncomment the code above after training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a603e",
   "metadata": {},
   "source": [
    "## 5. Test Inference\n",
    "\n",
    "Run inference on test images or videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on an image\n",
    "# results = model.predict(\n",
    "#     source='path/to/image.jpg',\n",
    "#     conf=0.25,  # confidence threshold\n",
    "#     iou=0.45,   # NMS IoU threshold\n",
    "#     show=True,  # display results\n",
    "#     save=True,  # save annotated images\n",
    "#     save_txt=True,  # save results to txt\n",
    "#     save_conf=True,  # save confidences in txt\n",
    "# )\n",
    "\n",
    "# Display results\n",
    "# for result in results:\n",
    "#     boxes = result.boxes  # Boxes object for bbox outputs\n",
    "#     masks = result.masks  # Masks object for segmentation masks\n",
    "#     probs = result.probs  # Class probabilities for classification\n",
    "#     result.show()  # display to screen\n",
    "#     result.save(filename='result.jpg')  # save to disk\n",
    "\n",
    "print(\"Inference ready. Uncomment the code above to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0683536",
   "metadata": {},
   "source": [
    "## 6. Export Model\n",
    "\n",
    "Export trained model to different formats (ONNX, TensorRT, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cdef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format\n",
    "# onnx_model = model.export(format='onnx', dynamic=True, simplify=True)\n",
    "\n",
    "# Export to TensorRT (requires TensorRT installation)\n",
    "# tensorrt_model = model.export(\n",
    "#     format='engine',\n",
    "#     device=0,\n",
    "#     half=True,  # FP16 precision\n",
    "#     workspace=4,  # max workspace size in GB\n",
    "# )\n",
    "\n",
    "# Save to models directory\n",
    "# import shutil\n",
    "# tensorrt_dest = Path('../models/tensorrt/detection/')\n",
    "# tensorrt_dest.mkdir(parents=True, exist_ok=True)\n",
    "# shutil.copy(tensorrt_model, tensorrt_dest / 'yolov8s.engine')\n",
    "\n",
    "print(\"Export ready. Uncomment the code above after training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a22341",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Results\n",
    "\n",
    "Plot training metrics and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training curves\n",
    "# from PIL import Image\n",
    "\n",
    "# results_dir = Path('runs/detect/yolov8_custom')\n",
    "# if (results_dir / 'results.png').exists():\n",
    "#     img = Image.open(results_dir / 'results.png')\n",
    "#     plt.figure(figsize=(16, 10))\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.title('Training Results')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "print(\"Visualization ready. Uncomment the code above after training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b0f54",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covers:\n",
    "1. ✅ Loading pre-trained YOLOv8 models\n",
    "2. ✅ Dataset preparation and configuration\n",
    "3. ✅ Training with custom parameters\n",
    "4. ✅ Model validation and metrics\n",
    "5. ✅ Inference on new images\n",
    "6. ✅ Model export (ONNX, TensorRT)\n",
    "7. ✅ Results visualization\n",
    "\n",
    "### Next Steps\n",
    "- Prepare your custom dataset in YOLO format\n",
    "- Adjust training parameters for your use case\n",
    "- Monitor training progress and metrics\n",
    "- Export trained model for deployment\n",
    "- Integrate with the AppStore detection app"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18681397",
   "metadata": {},
   "source": [
    "# YOLOv8 Object Tracking Training\n",
    "\n",
    "This notebook demonstrates tracking with YOLOv8 + StrongSORT and fine-tuning tracking models.\n",
    "\n",
    "## Requirements\n",
    "- ultralytics\n",
    "- boxmot (for StrongSORT)\n",
    "- PyTorch with CUDA support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068e49e",
   "metadata": {},
   "source": [
    "## 1. Load Detection Model for Tracking\n",
    "\n",
    "Tracking uses a detection model + tracking algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 detection model for tracking\n",
    "model_path = '../models/tracking/yolo/yolov8s.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(f\"Model loaded: {model_path}\")\n",
    "print(f\"Model task: {model.task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d4cd8",
   "metadata": {},
   "source": [
    "## 2. Basic Tracking with YOLOv8\n",
    "\n",
    "YOLOv8 has built-in tracking using BoT-SORT and ByteTrack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track objects in a video\n",
    "# results = model.track(\n",
    "#     source='path/to/video.mp4',\n",
    "#     show=True,\n",
    "#     save=True,\n",
    "#     tracker='botsort.yaml',  # or 'bytetrack.yaml'\n",
    "#     conf=0.3,\n",
    "#     iou=0.5,\n",
    "#     device=0,\n",
    "#     project='runs/track',\n",
    "#     name='yolov8_tracking',\n",
    "# )\n",
    "\n",
    "# Available trackers:\n",
    "trackers_info = \"\"\"\n",
    "Built-in YOLOv8 Trackers:\n",
    "1. BoT-SORT (botsort.yaml) - Better for crowded scenes\n",
    "2. ByteTrack (bytetrack.yaml) - Faster, good for real-time\n",
    "\n",
    "External Trackers (with boxmot):\n",
    "3. StrongSORT - Most accurate, uses Re-ID\n",
    "4. DeepOCSORT - Balance of speed and accuracy\n",
    "5. OCSORT - Fast, simple\n",
    "\"\"\"\n",
    "\n",
    "print(trackers_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a98bd6",
   "metadata": {},
   "source": [
    "## 3. StrongSORT Tracking\n",
    "\n",
    "StrongSORT provides better tracking with Re-ID features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install boxmot for StrongSORT\n",
    "# !pip install boxmot\n",
    "\n",
    "try:\n",
    "    from boxmot import StrongSORT\n",
    "    print(\"✓ BoxMOT (StrongSORT) is available\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ BoxMOT not installed. Run: pip install boxmot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd36a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrongSORT tracking configuration\n",
    "strongsort_config = {\n",
    "    'reid_model_path': '../models/tracking/strongsort/osnet_x0_25_msmt17.pt',\n",
    "    'device': 'cuda:0',\n",
    "    'fp16': True,  # Use half precision\n",
    "    'max_dist': 0.2,  # Maximum cosine distance\n",
    "    'max_iou_distance': 0.7,  # Maximum IOU distance\n",
    "    'max_age': 30,  # Maximum frames to keep alive a track\n",
    "    'n_init': 3,  # Number of frames to confirm a track\n",
    "    'nn_budget': 100,  # Maximum size of feature bank\n",
    "}\n",
    "\n",
    "print(\"StrongSORT Configuration:\")\n",
    "for key, value in strongsort_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StrongSORT with YOLOv8\n",
    "# def track_with_strongsort(video_path, model):\n",
    "#     from boxmot import StrongSORT\n",
    "#     \n",
    "#     # Initialize StrongSORT\n",
    "#     tracker = StrongSORT(\n",
    "#         model_weights=Path('../models/tracking/strongsort/osnet_x0_25_msmt17.pt'),\n",
    "#         device='cuda:0',\n",
    "#         fp16=True,\n",
    "#     )\n",
    "#     \n",
    "#     # Open video\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     \n",
    "#     # Get video properties\n",
    "#     fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#     \n",
    "#     # Output video writer\n",
    "#     out = cv2.VideoWriter(\n",
    "#         'output_strongsort.mp4',\n",
    "#         cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "#         fps, (width, height)\n",
    "#     )\n",
    "#     \n",
    "#     frame_idx = 0\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         \n",
    "#         # Run detection\n",
    "#         results = model(frame, verbose=False)\n",
    "#         \n",
    "#         # Get detections\n",
    "#         if len(results[0].boxes) > 0:\n",
    "#             dets = results[0].boxes.xyxy.cpu().numpy()\n",
    "#             confs = results[0].boxes.conf.cpu().numpy()\n",
    "#             class_ids = results[0].boxes.cls.cpu().numpy()\n",
    "#             \n",
    "#             # Update tracker\n",
    "#             tracks = tracker.update(dets, confs, class_ids, frame)\n",
    "#             \n",
    "#             # Draw tracks\n",
    "#             for track in tracks:\n",
    "#                 x1, y1, x2, y2, track_id, conf, cls = track\n",
    "#                 cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "#                 cv2.putText(frame, f'ID: {int(track_id)}', (int(x1), int(y1) - 10),\n",
    "#                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "#         \n",
    "#         out.write(frame)\n",
    "#         frame_idx += 1\n",
    "#         \n",
    "#         if frame_idx % 100 == 0:\n",
    "#             print(f\"Processed {frame_idx} frames\")\n",
    "#     \n",
    "#     cap.release()\n",
    "#     out.release()\n",
    "#     print(f\"\\n✓ Tracking complete! Output saved to output_strongsort.mp4\")\n",
    "\n",
    "# Example usage:\n",
    "# track_with_strongsort('path/to/video.mp4', model)\n",
    "\n",
    "print(\"StrongSORT tracking function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c2f40",
   "metadata": {},
   "source": [
    "## 4. Train Custom Tracking Dataset\n",
    "\n",
    "For tracking, you typically train a better detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde89dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters for tracking-optimized detection\n",
    "training_params = {\n",
    "    'data': 'path/to/data.yaml',\n",
    "    'epochs': 100,\n",
    "    'imgsz': 640,\n",
    "    'batch': 16,\n",
    "    'device': 0,\n",
    "    'project': 'runs/detect',\n",
    "    'name': 'yolov8_tracking_optimized',\n",
    "    'patience': 50,\n",
    "    # Tracking-specific optimizations\n",
    "    'conf': 0.25,  # Lower confidence for better recall\n",
    "    'iou': 0.45,\n",
    "    'augment': True,  # Important for tracking robustness\n",
    "    'mosaic': 1.0,  # Use mosaic augmentation\n",
    "    'mixup': 0.1,  # Use mixup augmentation\n",
    "}\n",
    "\n",
    "print(\"Tracking-optimized training parameters:\")\n",
    "for key, value in training_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93861ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model for tracking\n",
    "# results = model.train(**training_params)\n",
    "\n",
    "print(\"Training ready. Uncomment to start.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caadd4c",
   "metadata": {},
   "source": [
    "## 5. Evaluate Tracking Performance\n",
    "\n",
    "Tracking metrics: MOTA, MOTP, IDF1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking evaluation metrics\n",
    "tracking_metrics = \"\"\"\n",
    "Key Tracking Metrics:\n",
    "\n",
    "1. MOTA (Multiple Object Tracking Accuracy)\n",
    "   - Overall tracking accuracy considering FP, FN, ID switches\n",
    "   - Range: -∞ to 1 (higher is better)\n",
    "\n",
    "2. MOTP (Multiple Object Tracking Precision)\n",
    "   - Average distance between predictions and ground truth\n",
    "   - Lower is better\n",
    "\n",
    "3. IDF1 (ID F1 Score)\n",
    "   - Ratio of correctly identified detections\n",
    "   - Range: 0 to 1 (higher is better)\n",
    "\n",
    "4. ID Switches\n",
    "   - Number of times track IDs change\n",
    "   - Lower is better\n",
    "\n",
    "5. Fragmentation\n",
    "   - Number of times a track is interrupted\n",
    "   - Lower is better\n",
    "\"\"\"\n",
    "\n",
    "print(tracking_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841d148",
   "metadata": {},
   "source": [
    "## 6. Advanced Tracking Techniques\n",
    "\n",
    "Tips for better tracking performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices for tracking\n",
    "best_practices = \"\"\"\n",
    "Tracking Optimization Tips:\n",
    "\n",
    "1. Detection Quality:\n",
    "   - Use higher resolution (640-1280)\n",
    "   - Lower confidence threshold (0.2-0.3) for better recall\n",
    "   - Train on domain-specific data\n",
    "\n",
    "2. Tracker Selection:\n",
    "   - ByteTrack: Fast, real-time applications\n",
    "   - BoT-SORT: Crowded scenes, occlusions\n",
    "   - StrongSORT: Best accuracy, Re-ID features\n",
    "\n",
    "3. Re-ID Model:\n",
    "   - OSNet: General purpose\n",
    "   - ResNet: More accurate but slower\n",
    "   - MobileNet: Faster but less accurate\n",
    "\n",
    "4. Hyperparameters:\n",
    "   - max_age: Increase for slow-moving objects\n",
    "   - n_init: Decrease for fast initialization\n",
    "   - iou_threshold: Adjust based on object overlap\n",
    "\n",
    "5. Post-processing:\n",
    "   - Track smoothing (Kalman filter)\n",
    "   - Interpolation for missing frames\n",
    "   - Track merging for split tracks\n",
    "\"\"\"\n",
    "\n",
    "print(best_practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac9c3d",
   "metadata": {},
   "source": [
    "## 7. Export Tracking Model\n",
    "\n",
    "Export optimized model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to TensorRT for faster tracking\n",
    "# tensorrt_model = model.export(\n",
    "#     format='engine',\n",
    "#     device=0,\n",
    "#     half=True,\n",
    "#     workspace=4,\n",
    "# )\n",
    "\n",
    "# Save to models directory\n",
    "# import shutil\n",
    "# tensorrt_dest = Path('../models/tensorrt/tracking/')\n",
    "# tensorrt_dest.mkdir(parents=True, exist_ok=True)\n",
    "# shutil.copy(tensorrt_model, tensorrt_dest / 'yolov8s_tracking.engine')\n",
    "\n",
    "print(\"Export ready. Uncomment after training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115fb04",
   "metadata": {},
   "source": [
    "## 8. Real-time Tracking Demo\n",
    "\n",
    "Process webcam or RTSP stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42164aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time tracking from webcam\n",
    "# def realtime_tracking():\n",
    "#     cap = cv2.VideoCapture(0)  # Webcam\n",
    "#     \n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         \n",
    "#         # Track objects\n",
    "#         results = model.track(frame, persist=True, verbose=False)\n",
    "#         \n",
    "#         # Visualize\n",
    "#         annotated = results[0].plot()\n",
    "#         \n",
    "#         cv2.imshow('YOLOv8 Tracking', annotated)\n",
    "#         \n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     \n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "# realtime_tracking()\n",
    "\n",
    "print(\"Real-time tracking function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdb741",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covers:\n",
    "1. ✅ Loading YOLOv8 models for tracking\n",
    "2. ✅ Built-in tracking (BoT-SORT, ByteTrack)\n",
    "3. ✅ StrongSORT integration with Re-ID\n",
    "4. ✅ Training tracking-optimized detectors\n",
    "5. ✅ Tracking evaluation metrics\n",
    "6. ✅ Best practices and optimization tips\n",
    "7. ✅ Model export for deployment\n",
    "8. ✅ Real-time tracking implementation\n",
    "\n",
    "### Next Steps\n",
    "- Download StrongSORT Re-ID model\n",
    "- Test different trackers on your videos\n",
    "- Fine-tune detection model for your domain\n",
    "- Optimize hyperparameters for your use case\n",
    "- Integrate with AppStore tracking app"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
